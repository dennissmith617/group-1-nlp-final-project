{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27facbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7dcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac66c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_json(\"200k_questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35de3240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'This Puccini opera turns on the solution to 3...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Turandot</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In North America this term is properly applie...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>a titmouse</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In Penny Lane, where this \"Hellraiser\" grew u...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Clive Barker</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'From Ft. Sill, Okla. he made the plea, Arizon...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'A silent movie title includes the last name o...</td>\n",
       "      <td>None</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               category    air_date  \\\n",
       "0                               HISTORY  2004-12-31   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2           EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                      THE COMPANY LINE  2004-12-31   \n",
       "4                   EPITAPHS & TRIBUTES  2004-12-31   \n",
       "...                                 ...         ...   \n",
       "216925                   RIDDLE ME THIS  2006-05-11   \n",
       "216926                        \"T\" BIRDS  2006-05-11   \n",
       "216927           AUTHORS IN THEIR YOUTH  2006-05-11   \n",
       "216928                       QUOTATIONS  2006-05-11   \n",
       "216929                   HISTORIC NAMES  2006-05-11   \n",
       "\n",
       "                                                 question  value  \\\n",
       "0       'For the last 8 years of his life, Galileo was...   $200   \n",
       "1       'No. 2: 1912 Olympian; football star at Carlis...   $200   \n",
       "2       'The city of Yuma in this state has a record a...   $200   \n",
       "3       'In 1963, live on \"The Art Linkletter Show\", t...   $200   \n",
       "4       'Signer of the Dec. of Indep., framer of the C...   $200   \n",
       "...                                                   ...    ...   \n",
       "216925  'This Puccini opera turns on the solution to 3...  $2000   \n",
       "216926  'In North America this term is properly applie...  $2000   \n",
       "216927  'In Penny Lane, where this \"Hellraiser\" grew u...  $2000   \n",
       "216928  'From Ft. Sill, Okla. he made the plea, Arizon...  $2000   \n",
       "216929  'A silent movie title includes the last name o...   None   \n",
       "\n",
       "                                answer             round  show_number  \n",
       "0                           Copernicus         Jeopardy!         4680  \n",
       "1                           Jim Thorpe         Jeopardy!         4680  \n",
       "2                              Arizona         Jeopardy!         4680  \n",
       "3                          McDonald\\'s         Jeopardy!         4680  \n",
       "4                           John Adams         Jeopardy!         4680  \n",
       "...                                ...               ...          ...  \n",
       "216925                        Turandot  Double Jeopardy!         4999  \n",
       "216926                      a titmouse  Double Jeopardy!         4999  \n",
       "216927                    Clive Barker  Double Jeopardy!         4999  \n",
       "216928                        Geronimo  Double Jeopardy!         4999  \n",
       "216929  Grigori Alexandrovich Potemkin   Final Jeopardy!         4999  \n",
       "\n",
       "[216930 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd08c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean columns\n",
    "questions.columns = questions.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec5bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category, air_date, question, value, answer, round, show_number]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and verify no missing/imcomplete data\n",
    "questions[(questions.isna().any(axis=1)) & (questions['round'] != 'Final Jeopardy!') & (questions['round'] != 'Tiebreaker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c09a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category        27995\n",
       "air_date         3640\n",
       "question       216132\n",
       "value             149\n",
       "answer          88269\n",
       "round               4\n",
       "show_number      3640\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4fda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Columns\n",
    "questions['air_date'] = pd.to_datetime(questions['air_date'])\n",
    "\n",
    "questions['value'] = questions['value'].str.replace(\"$\",\"\")\n",
    "questions['value'] = questions['value'].str.replace(\",\",\"\")\n",
    "questions['value'] = questions['value'].fillna('0')\n",
    "questions['value'] = questions['value'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d39508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206362</th>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'This Puccini opera turns on the solution to 3...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Turandot</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206363</th>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In North America this term is properly applie...</td>\n",
       "      <td>2000</td>\n",
       "      <td>a titmouse</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206364</th>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In Penny Lane, where this \"Hellraiser\" grew u...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Clive Barker</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206365</th>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'From Ft. Sill, Okla. he made the plea, Arizon...</td>\n",
       "      <td>2000</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206366</th>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'A silent movie title includes the last name o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206367 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               category   air_date  \\\n",
       "0                               HISTORY 2004-12-31   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES 2004-12-31   \n",
       "2           EVERYBODY TALKS ABOUT IT... 2004-12-31   \n",
       "3                      THE COMPANY LINE 2004-12-31   \n",
       "4                   EPITAPHS & TRIBUTES 2004-12-31   \n",
       "...                                 ...        ...   \n",
       "206362                   RIDDLE ME THIS 2006-05-11   \n",
       "206363                        \"T\" BIRDS 2006-05-11   \n",
       "206364           AUTHORS IN THEIR YOUTH 2006-05-11   \n",
       "206365                       QUOTATIONS 2006-05-11   \n",
       "206366                   HISTORIC NAMES 2006-05-11   \n",
       "\n",
       "                                                 question  value  \\\n",
       "0       'For the last 8 years of his life, Galileo was...    200   \n",
       "1       'No. 2: 1912 Olympian; football star at Carlis...    200   \n",
       "2       'The city of Yuma in this state has a record a...    200   \n",
       "3       'In 1963, live on \"The Art Linkletter Show\", t...    200   \n",
       "4       'Signer of the Dec. of Indep., framer of the C...    200   \n",
       "...                                                   ...    ...   \n",
       "206362  'This Puccini opera turns on the solution to 3...   2000   \n",
       "206363  'In North America this term is properly applie...   2000   \n",
       "206364  'In Penny Lane, where this \"Hellraiser\" grew u...   2000   \n",
       "206365  'From Ft. Sill, Okla. he made the plea, Arizon...   2000   \n",
       "206366  'A silent movie title includes the last name o...      0   \n",
       "\n",
       "                                answer             round  show_number  \n",
       "0                           Copernicus         Jeopardy!         4680  \n",
       "1                           Jim Thorpe         Jeopardy!         4680  \n",
       "2                              Arizona         Jeopardy!         4680  \n",
       "3                          McDonald\\'s         Jeopardy!         4680  \n",
       "4                           John Adams         Jeopardy!         4680  \n",
       "...                                ...               ...          ...  \n",
       "206362                        Turandot  Double Jeopardy!         4999  \n",
       "206363                      a titmouse  Double Jeopardy!         4999  \n",
       "206364                    Clive Barker  Double Jeopardy!         4999  \n",
       "206365                        Geronimo  Double Jeopardy!         4999  \n",
       "206366  Grigori Alexandrovich Potemkin   Final Jeopardy!         4999  \n",
       "\n",
       "[206367 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = questions[questions['question'].str.contains('www')==False].reset_index(drop=True)\n",
    "questions = questions[questions['category'].str.contains('missing')==False].reset_index(drop=True)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6143862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amary\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# skipgram and cbow\n",
    "\n",
    "# preprocess text\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [re.sub(r'[^a-zA-Z0-9]', '', token) for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Preprocess and tokenize Jeopardy questions\n",
    "preprocessed_questions = [(preprocess_text(question), category) for question, category in zip(questions['question'], questions['category'])][:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3a561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Skip-gram model\n",
    "sentences = [tokens for tokens, _ in preprocessed_questions]\n",
    "skipgram_model = Word2Vec(sentences, sg=1, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate embeddings for each question using Skip-gram\n",
    "def generate_skipgram_embedding(tokens, model):\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv.key_to_index:\n",
    "            embeddings.append(model.wv[token])\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(model.vector_size)  # If no embeddings found, return zeros\n",
    "    return np.mean(embeddings, axis=0)  # Average embeddings for all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958afbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CBOW model\n",
    "cbow_model = Word2Vec(sentences, sg=0, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Generate embeddings for each question using CBOW\n",
    "def generate_cbow_embedding(tokens, model):\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv.key_to_index:\n",
    "            embeddings.append(model.wv[token])\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(model.vector_size)  # If no embeddings found, return zeros\n",
    "    return np.mean(embeddings, axis=0)  # Average embeddings for all tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bbe14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_skipgram = np.array([generate_skipgram_embedding(tokens, skipgram_model) for tokens, _ in preprocessed_questions])\n",
    "X_cbow = np.array([generate_cbow_embedding(tokens, cbow_model) for tokens, _ in preprocessed_questions])\n",
    "y = np.array([category for _, category in preprocessed_questions])\n",
    "\n",
    "# Split data into train and test sets for Skip-gram\n",
    "X_train_skipgram, X_test_skipgram, y_train, y_test = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data into train and test sets for CBOW\n",
    "X_train_cbow, X_test_cbow, _, _ = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae932094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression classifier for Skip-gram\n",
    "classifier_skipgram = LogisticRegression(max_iter=50)\n",
    "classifier_skipgram.fit(X_train_skipgram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_cbow = LogisticRegression(max_iter=50)\n",
    "classifier_cbow.fit(X_train_cbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "954b98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set for Skip-gram\n",
    "y_pred_skipgram = classifier_skipgram.predict(X_test_skipgram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0792af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set for CBOW\n",
    "y_pred_cbow = classifier_cbow.predict(X_test_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82102a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Skip-gram: 0.03105\n",
      "Accuracy for CBOW: 0.0189\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy for Skip-gram\n",
    "accuracy_skipgram = accuracy_score(y_test, y_pred_skipgram)\n",
    "print(\"Accuracy for Skip-gram:\", accuracy_skipgram)\n",
    "\n",
    "# Evaluate accuracy for CBOW\n",
    "accuracy_cbow = accuracy_score(y_test, y_pred_cbow)\n",
    "print(\"Accuracy for CBOW:\", accuracy_cbow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
